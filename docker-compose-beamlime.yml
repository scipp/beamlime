name: beamlime-kafka
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: kafka-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_MAX_CLIENT_CNXNS: 20
    mem_limit: 512M

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-broker
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: false
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # Performance optimizations for local development
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 1
      KAFKA_NUM_NETWORK_THREADS: 2
      KAFKA_NUM_IO_THREADS: 4
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 104857600
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 104857600
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_MAX_CONNECTIONS_PER_IP: 100
      # Memory settings
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"
      # Disk usage limits
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB total retention
      KAFKA_LOG_RETENTION_HOURS: 1           # Keep logs for 1 hours
      KAFKA_LOG_SEGMENT_BYTES: 268435456     # 256MB per segment
      KAFKA_LOG_CLEANUP_POLICY: delete       # Delete old segments
      KAFKA_LOG_CLEANER_MIN_CLEANABLE_RATIO: 0.5
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000  # Check every 5 minutes
      KAFKA_MESSAGE_MAX_BYTES: 20971520          # 20MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 20971520    # 20MB
      KAFKA_REPLICA_SOCKET_RECEIVE_BUFFER_BYTES: 20971520
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 20971520    # 20MB
      KAFKA_MAX_REQUEST_SIZE: 20971520           # 20MB
      KAFKA_MAX_PARTITION_FETCH_BYTES: 20971520  # 20MB
    mem_limit: 1G
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3

  init-kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
    command: ["sh", "/scripts/setup-kafka-topics.sh", "${BEAMLIME_INSTRUMENT:-dummy}"]

  fake-producer:
    image: python:3.12
    container_name: fake-producer
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.fake_producer --mode ev44 --instrument $BEAMLIME_INSTRUMENT"

  monitor-data:
    image: python:3.12
    container_name: monitor-data
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.monitor_data --mode ev44 --instrument $BEAMLIME_INSTRUMENT"

  dashboard:
    image: python:3.12
    container_name: dashboard
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    ports:
      - "8000:8000"
    environment:
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
    command: sh -c "python -m pip install -e .[dashboard] && gunicorn beamlime.services.wsgi:application -b 0.0.0.0:8000"
