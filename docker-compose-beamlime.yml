name: beamlime-kafka
services:
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-broker
    ports:
      - "9092:9092"
    volumes:
      - ./scripts:/scripts
    environment:
      KAFKA_CONFLUENT_SUPPORT_METRICS_ENABLE: false
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_INTERNAL://0.0.0.0:29092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 1
      KAFKA_LOG_DIRS: /tmp/kraft-combined-logs
      CLUSTER_ID: 4L6g3nShT-eMCtK--X86sw
      # Performance optimizations for local development
      KAFKA_NUM_RECOVERY_THREADS_PER_DATA_DIR: 1
      KAFKA_NUM_NETWORK_THREADS: 2
      KAFKA_NUM_IO_THREADS: 4
      # KRaft-specific timeout adjustments
      KAFKA_CONTROLLER_SOCKET_TIMEOUT_MS: 30000
      KAFKA_CONTROLLER_REQUEST_TIMEOUT_MS: 30000
      KAFKA_METADATA_MAX_IDLE_INTERVAL_MS: 500
      # Reduce log retention for development
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 104857600
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 204857600
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_MAX_CONNECTIONS_PER_IP: 100
      # Memory settings - increased to handle group coordinator pressure
      KAFKA_HEAP_OPTS: "-Xmx3G -Xms3G"
      # More aggressive cleanup to prevent memory buildup
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB total retention
      KAFKA_LOG_RETENTION_HOURS: 1           # Keep logs for 1 hours
      KAFKA_LOG_SEGMENT_BYTES: 67108864      # 64MB per segment (smaller for faster cleanup)
      KAFKA_LOG_CLEANUP_POLICY: delete       # Delete old segments
      KAFKA_LOG_CLEANER_MIN_CLEANABLE_RATIO: 0.1
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 30000   # Check every 30 seconds for faster cleanup
      KAFKA_LOG_CLEANER_ENABLE: true
      KAFKA_LOG_CLEANER_THREADS: 2
      # Group coordinator optimizations to prevent rebalancing loops
      KAFKA_OFFSETS_RETENTION_MINUTES: 60    # Clean up consumer group metadata after 1 hour
      KAFKA_OFFSETS_RETENTION_CHECK_INTERVAL_MS: 60000
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 10  # Reduce from default 50 to lower coordinator load
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_OFFSETS_TOPIC_SEGMENT_BYTES: 104857600
      KAFKA_OFFSETS_LOAD_BUFFER_SIZE: 5242880
      KAFKA_OFFSETS_COMMIT_TIMEOUT_MS: 5000
      KAFKA_OFFSETS_COMMIT_REQUIRED_ACKS: 1
      # Group coordinator session timeouts to prevent hanging operations
      KAFKA_GROUP_MIN_SESSION_TIMEOUT_MS: 6000
      KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS: 1800000
      KAFKA_GROUP_MAX_SIZE: 100
      # Additional stability settings
      KAFKA_CONNECTIONS_MAX_IDLE_MS: 600000
      KAFKA_REQUEST_TIMEOUT_MS: 30000
      # Message size limits (keeping as requested)
      KAFKA_MESSAGE_MAX_BYTES: 104857600          # 100MB
      KAFKA_REPLICA_FETCH_MAX_BYTES: 104857600    # 100MB
      KAFKA_REPLICA_SOCKET_RECEIVE_BUFFER_BYTES: 104857600
      KAFKA_FETCH_MESSAGE_MAX_BYTES: 104857600    # 100MB
      KAFKA_MAX_REQUEST_SIZE: 104857600           # 100MB
      KAFKA_MAX_PARTITION_FETCH_BYTES: 104857600  # 100MB
    mem_limit: 5G
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3

  init-kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ./scripts:/scripts
    command: ["sh", "/scripts/setup-kafka-topics.sh", "${BEAMLIME_INSTRUMENT:-dummy}"]

  fake-monitors:
    profiles:
      - monitor  # Only run fake producer with `docker compose --profile monitor up`
    image: python:3.12
    container_name: fake-monitors
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.fake_monitors --mode ev44 --instrument $BEAMLIME_INSTRUMENT"

  fake-detectors:
    profiles:
      - detector
    image: python:3.12
    container_name: fake-detectors
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.fake_detectors --instrument $BEAMLIME_INSTRUMENT"

  monitor-data:
    profiles:
      - monitor
    image: python:3.12
    container_name: monitor-data
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
      KAFKA2_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA2_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA2_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA2_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA2_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.monitor_data --instrument $BEAMLIME_INSTRUMENT"

  detector-data:
    profiles:
      - detector
    image: python:3.12
    container_name: detector-data
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
      KAFKA2_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA2_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA2_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA2_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA2_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e . && python -m beamlime.services.detector_data --instrument $BEAMLIME_INSTRUMENT"

  monitors-dashboard:
    profiles:
      - monitor
    image: python:3.12
    container_name: monitors-dashboard
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    ports:
      - "5007:5007"
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
      KAFKA2_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA2_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA2_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA2_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA2_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e .[dashboard] && gunicorn beamlime.dashboard.monitors_wsgi:application -b 0.0.0.0:5007"

  reduction-dashboard:
    profiles:
      - reduction
    image: python:3.12
    container_name: reduction-dashboard
    depends_on:
      init-kafka:
        condition: service_completed_successfully
      kafka:
        condition: service_healthy
    volumes:
      - .:/app
    working_dir: /app
    ports:
      - "5009:5009"
    environment:
      BEAMLIME_ENV: docker
      BEAMLIME_INSTRUMENT: ${BEAMLIME_INSTRUMENT:-dummy}
      KAFKA_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
      KAFKA2_BOOTSTRAP_SERVERS: ${KAFKA_BOOTSTRAP_SERVERS:-kafka:29092}
      KAFKA2_SECURITY_PROTOCOL: ${KAFKA_SECURITY_PROTOCOL:-PLAINTEXT}
      KAFKA2_SASL_MECHANISM: ${KAFKA_SASL_MECHANISM:-SCRAM-SHA-256}
      KAFKA2_SASL_USERNAME: ${KAFKA_SASL_USERNAME:-DUMMY}
      KAFKA2_SASL_PASSWORD: ${KAFKA_SASL_PASSWORD:-DUMMY}
    command: sh -c "python -m pip install -e .[dashboard] && gunicorn beamlime.dashboard.reduction_wsgi:application -b 0.0.0.0:5009"
